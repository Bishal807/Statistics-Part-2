{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Types of Data (Qualitative & Quantitative)\n",
        "Qualitative (Categorical): Describes qualities or categories.\n",
        "\n",
        "Examples: Eye color, type of car, gender.\n",
        "\n",
        "Quantitative (Numerical): Measurable quantities.\n",
        "\n",
        "Examples: Height, weight, temperature.\n",
        "\n",
        "Scales:\n",
        "\n",
        "Nominal: Categories without order (e.g., colors).\n",
        "\n",
        "Ordinal: Categories with order (e.g., ranks).\n",
        "\n",
        "Interval: Ordered, equal intervals, no true zero (e.g., temperature in °C).\n",
        "\n",
        "Ratio: Like interval, but with a true zero (e.g., weight, height).\n",
        "\n",
        "2. Measures of Central Tendency\n",
        "Mean: Arithmetic average; used when data is symmetrically distributed.\n",
        "\n",
        "Median: Middle value; useful for skewed data.\n",
        "\n",
        "Mode: Most frequent value; good for categorical data.\n",
        "\n",
        "3. Dispersion\n",
        "Describes data spread.\n",
        "\n",
        "Variance: Average of squared deviations from the mean.\n",
        "\n",
        "Standard Deviation (SD): Square root of variance; more interpretable.\n",
        "\n",
        "4. Box Plot\n",
        "Visual representation showing:\n",
        "\n",
        "Median, quartiles, min/max, and outliers.\n",
        "\n",
        "Helps detect skewness and outliers.\n",
        "\n",
        "5. Random Sampling\n",
        "Ensures each individual has an equal chance of selection, helping generalize results to the entire population.\n",
        "\n",
        "6. Skewness\n",
        "Indicates data asymmetry.\n",
        "\n",
        "Positive skew: Tail on the right.\n",
        "\n",
        "Negative skew: Tail on the left.\n",
        "Skewness affects the mean and interpretation.\n",
        "\n",
        "7. Interquartile Range (IQR)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "Detects outliers (data points < Q1 - 1.5×IQR or > Q3 + 1.5×IQR)\n",
        "\n",
        "8. Binomial Distribution Conditions\n",
        "Fixed number of trials\n",
        "\n",
        "Two outcomes (success/failure)\n",
        "\n",
        "Constant probability\n",
        "\n",
        "Independent trials\n",
        "\n",
        "9. Normal Distribution & Empirical Rule\n",
        "Bell-shaped, symmetric curve\n",
        "\n",
        "68-95-99.7 rule:\n",
        "\n",
        "68% within 1 SD\n",
        "\n",
        "95% within 2 SDs\n",
        "\n",
        "99.7% within 3 SDs\n",
        "\n",
        "10. Poisson Process Example\n",
        "Call center receiving calls per minute\n",
        "If λ = 5 calls/min:\n",
        "P(X=3) = (e^–5 × 5^3) / 3! = 0.1404\n",
        "\n",
        "11. Random Variables\n",
        "Discrete: Countable (e.g., no. of kids)\n",
        "\n",
        "Continuous: Measurable (e.g., height)\n",
        "\n",
        "12. Variance & Correlation Example\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import numpy as np\n",
        "\n",
        "x = [2, 4, 6, 8]\n",
        "y = [1, 3, 5, 7]\n",
        "\n",
        "print(\"Variance of x:\", np.var(x))\n",
        "print(\"Covariance matrix:\\n\", np.cov(x, y))\n",
        "print(\"Correlation coefficient:\", np.corrcoef(x, y)[0,1])\n",
        "Next, I’ll continue with the Hypothesis Testing Theoretical Questions (Screenshot 4) in the following message. Let me know if you want the practical implementations (Python code) right after that or side-by-side.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "You said:\n",
        "ok\n",
        "\n",
        "\n",
        "ChatGPT said:\n",
        "Great! Let’s now continue with Theoretical Questions on Hypothesis Testing from Screenshot 4:\n",
        "\n",
        "1. What is hypothesis testing in statistics?\n",
        "It is a method to make inferences about a population using sample data. It involves testing an assumption (hypothesis) to determine if there's enough evidence to reject it.\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "Null Hypothesis (H₀): Assumes no effect or difference.\n",
        "\n",
        "Alternative Hypothesis (H₁): Assumes an effect or difference exists.\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "Significance Level (α): Probability of rejecting H₀ when it's true (Type I error).\n",
        "\n",
        "Common values: 0.05, 0.01.\n",
        "\n",
        "4–5. What does a P-value represent, and how do you interpret it?\n",
        "P-value: Probability of observing the test results if H₀ is true.\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If P ≤ α → reject H₀\n",
        "\n",
        "If P > α → fail to reject H₀\n",
        "\n",
        "6. Type I and Type II Errors\n",
        "Type I Error (False Positive): Rejecting true H₀.\n",
        "\n",
        "Type II Error (False Negative): Failing to reject false H₀.\n",
        "\n",
        "7. One-tailed vs. Two-tailed Tests\n",
        "One-tailed: Tests for direction (e.g., greater than).\n",
        "\n",
        "Two-tailed: Tests for any difference (≠).\n",
        "\n",
        "8. What is the Z-test, and when is it used?\n",
        "Used when:\n",
        "\n",
        "Sample size ≥ 30\n",
        "\n",
        "Population variance known\n",
        "\n",
        "Data is approximately normal\n",
        "\n",
        "9. How to calculate the Z-score?\n",
        "Z = (X̄ – μ) / (σ / √n)\n",
        "\n",
        "Measures how far a sample mean is from population mean.\n",
        "\n",
        "10. What is the T-distribution and when should it be used?\n",
        "Used when:\n",
        "\n",
        "Sample size < 30\n",
        "\n",
        "Population standard deviation unknown\n",
        "It has heavier tails than normal distribution.\n",
        "\n",
        "11. Difference between Z-test and T-test\n",
        "Z-test: Known variance, large sample.\n",
        "\n",
        "T-test: Unknown variance, small sample.\n",
        "\n",
        "12. What is the T-test, and how is it used?\n",
        "Used to compare means:\n",
        "\n",
        "One-sample: Sample vs population\n",
        "\n",
        "Two-sample: Between two independent samples\n",
        "\n",
        "Paired: Before and after same subjects\n",
        "\n",
        "13. Relationship between Z-test and T-test\n",
        "Both compare means, but T-test adjusts for small sample uncertainty using T-distribution.\n",
        "\n",
        "14. Confidence Interval (CI)\n",
        "Range of values likely to contain the true parameter.\n",
        "E.g., \"We are 95% confident that the true mean lies between X and Y.\"\n",
        "\n",
        "15. Margin of Error\n",
        "Half-width of confidence interval.\n",
        "Affected by:\n",
        "\n",
        "Sample size\n",
        "\n",
        "Variability\n",
        "\n",
        "Confidence level\n",
        "\n",
        "16. Bayes' Theorem\n",
        "Used to update probability based on new evidence.\n",
        "In statistics, it enables Bayesian inference:\n",
        "P(A|B) = [P(B|A) × P(A)] / P(B)\n",
        "\n",
        "17. Chi-square Distribution\n",
        "Used for:\n",
        "\n",
        "Goodness-of-fit\n",
        "\n",
        "Independence test in contingency tables\n",
        "\n",
        "18. Chi-square Goodness-of-fit Test\n",
        "Tests if sample data fits a specific distribution.\n",
        "\n",
        "19. What is the F-distribution?\n",
        "Used to compare variances of two populations. Basis of ANOVA.\n",
        "\n",
        "20. What is ANOVA?\n",
        "Analysis of Variance – Compares means across ≥2 groups.\n",
        "\n",
        "One-way: One factor\n",
        "\n",
        "Two-way: Two factors + interaction\n",
        "\n",
        "21. Different Types of ANOVA\n",
        "One-way ANOVA\n",
        "\n",
        "Two-way ANOVA\n",
        "\n",
        "Repeated Measures ANOVA\n",
        "\n",
        "22. F-test vs ANOVA\n",
        "F-test compares two variances. ANOVA uses F-statistic to compare means across groups."
      ],
      "metadata": {
        "id": "eMima-egPUko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZDn9KB9KryT",
        "outputId": "d2bcf7eb-dec3-42ce-eca4-e57de4c66856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-score: 2.3570\n",
            "P-value: 0.0184\n",
            "Reject the null hypothesis at α=0.05. There is a significant difference.\n"
          ]
        }
      ],
      "source": [
        "                                                        #pratical questions\n",
        "\n",
        "#1\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_mean: Mean of the sample\n",
        "    - population_mean: Known population mean to compare against\n",
        "    - population_std: Known population standard deviation\n",
        "    - sample_size: Number of observations in the sample\n",
        "    - alpha: Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - z_score: Computed Z statistic\n",
        "    - p_value: Two-tailed p-value for the test\n",
        "    - interpretation: Conclusion based on the p-value and alpha\n",
        "    \"\"\"\n",
        "    # Calculate standard error\n",
        "    standard_error = population_std / math.sqrt(sample_size)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Interpret the result\n",
        "    if p_value < alpha:\n",
        "        interpretation = f\"Reject the null hypothesis at α={alpha}. There is a significant difference.\"\n",
        "    else:\n",
        "        interpretation = f\"Fail to reject the null hypothesis at α={alpha}. No significant difference found.\"\n",
        "\n",
        "    return z_score, p_value, interpretation\n",
        "\n",
        "# Example usage\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 50\n",
        "alpha = 0.05\n",
        "\n",
        "z, p, result = z_test(sample_mean, population_mean, population_std, sample_size, alpha)\n",
        "print(f\"Z-score: {z:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Simulate random data\n",
        "np.random.seed(42)  # For reproducibility\n",
        "sample_size = 100\n",
        "population_mean = 50\n",
        "population_std = 10\n",
        "\n",
        "# Generate sample data with a true mean slightly different than population_mean\n",
        "true_sample_mean = 52\n",
        "sample_data = np.random.normal(loc=true_sample_mean, scale=population_std, size=sample_size)\n",
        "\n",
        "# Calculate sample statistics\n",
        "sample_mean = np.mean(sample_data)\n",
        "\n",
        "# Function to perform Z-test\n",
        "def z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    standard_error = population_std / math.sqrt(sample_size)\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))  # two-tailed test\n",
        "    return z_score, p_value\n",
        "\n",
        "z_score, p_value = z_test(sample_mean, population_mean, population_std, sample_size)\n",
        "\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: no significant difference found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVPkB8BRQGk3",
        "outputId": "3562bdfb-29a3-4f8d-e0b2-a73612c4cd41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Mean: 50.96\n",
            "Z-score: 0.9615\n",
            "P-value: 0.3363\n",
            "Fail to reject the null hypothesis: no significant difference found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "import math\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_mean: Mean of the sample data\n",
        "    - population_mean: Known population mean to compare with\n",
        "    - population_std: Known population standard deviation\n",
        "    - sample_size: Number of observations in the sample\n",
        "    - alpha: Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "    - z_stat: Z statistic\n",
        "    - p_value: Two-tailed p-value\n",
        "    - conclusion: Test conclusion string\n",
        "    \"\"\"\n",
        "    # Calculate the standard error\n",
        "    standard_error = population_std / math.sqrt(sample_size)\n",
        "\n",
        "    # Calculate the Z statistic\n",
        "    z_stat = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate the two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Interpret the result\n",
        "    if p_value < alpha:\n",
        "        conclusion = f\"Reject the null hypothesis (p = {p_value:.4f} < {alpha}). Significant difference found.\"\n",
        "    else:\n",
        "        conclusion = f\"Fail to reject the null hypothesis (p = {p_value:.4f} >= {alpha}). No significant difference found.\"\n",
        "\n",
        "    return z_stat, p_value, conclusion\n",
        "\n",
        "# Example values\n",
        "sample_mean = 103\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 30\n",
        "\n",
        "z_stat, p_val, conclusion = one_sample_z_test(sample_mean, population_mean, population_std, sample_size)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "print(conclusion)\n"
      ],
      "metadata": {
        "id": "5tAxzq0gQaAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "def two_tailed_z_test(sample_mean, population_mean, population_std, sample_size, alpha=0.05):\n",
        "    # Calculate standard error\n",
        "    standard_error = population_std / math.sqrt(sample_size)\n",
        "\n",
        "    # Calculate Z-score\n",
        "    z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "    # Critical z-value for two-tailed test\n",
        "    z_critical = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    # Determine if we reject null hypothesis\n",
        "    reject_null = abs(z_score) > z_critical\n",
        "\n",
        "    return z_score, p_value, z_critical, reject_null\n",
        "\n",
        "# Example data\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "sample_size = 40\n",
        "alpha = 0.05\n",
        "\n",
        "z_score, p_value, z_critical, reject_null = two_tailed_z_test(sample_mean, population_mean, population_std, sample_size, alpha)\n",
        "\n",
        "print(f\"Z-score: {z_score:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Critical Z-value: ±{z_critical:.4f}\")\n",
        "print(\"Reject Null Hypothesis:\" if reject_null else \"Fail to Reject Null Hypothesis\")\n",
        "\n",
        "# Plotting\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "# Shade rejection regions\n",
        "plt.fill_between(x, 0, y, where=(x <= -z_critical), color='red', alpha=0.3, label='Rejection Region')\n",
        "plt.fill_between(x, 0, y, where=(x >= z_critical), color='red', alpha=0.3)\n",
        "\n",
        "# Mark Z-score on the plot\n",
        "plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "plt.title('Two-tailed Z-test Decision Regions')\n",
        "plt.xlabel('Z value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#5\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "def plot_type1_type2_errors(pop_mean, pop_std, sample_size, alpha, true_mean):\n",
        "    \"\"\"\n",
        "    Visualize Type 1 and Type 2 errors in a hypothesis test.\n",
        "\n",
        "    Parameters:\n",
        "    - pop_mean: Mean under null hypothesis (H0)\n",
        "    - pop_std: Population standard deviation (assumed known)\n",
        "    - sample_size: Number of samples\n",
        "    - alpha: Significance level (Type 1 error rate)\n",
        "    - true_mean: Actual mean under alternative hypothesis (H1)\n",
        "    \"\"\"\n",
        "\n",
        "    se = pop_std / math.sqrt(sample_size)  # Standard error\n",
        "    z_critical = norm.ppf(1 - alpha)  # Critical value for one-tailed test\n",
        "\n",
        "    # Critical value cutoff in sample mean scale\n",
        "    cutoff = pop_mean + z_critical * se\n",
        "\n",
        "    # Define x range for plotting\n",
        "    x = np.linspace(pop_mean - 4*se, true_mean + 4*se, 1000)\n",
        "\n",
        "    # Null distribution (H0)\n",
        "    h0_pdf = norm.pdf(x, pop_mean, se)\n",
        "\n",
        "    # Alternative distribution (H1)\n",
        "    h1_pdf = norm.pdf(x, true_mean, se)\n",
        "\n",
        "    # Calculate Type 2 error (β): Probability of not rejecting H0 when H1 is true\n",
        "    beta = norm.cdf(cutoff, true_mean, se)\n",
        "\n",
        "    # Plot distributions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(x, h0_pdf, label='Null Hypothesis (H0)', color='blue')\n",
        "    plt.plot(x, h1_pdf, label='Alternative Hypothesis (H1)', color='green')\n",
        "\n",
        "    # Shade Type 1 error region (reject H0 when H0 true)\n",
        "    x_type1 = np.linspace(cutoff, pop_mean + 4*se, 1000)\n",
        "    plt.fill_between(x_type1, 0, norm.pdf(x_type1, pop_mean, se), color='red', alpha=0.3, label='Type 1 Error (α)')\n",
        "\n",
        "    # Shade Type 2 error region (fail to reject H0 when H1 true)\n",
        "    x_type2 = np.linspace(pop_mean - 4*se, cutoff, 1000)\n",
        "    plt.fill_between(x_type2, 0, norm.pdf(x_type2, true_mean, se), color='orange', alpha=0.3, label='Type 2 Error (β)')\n",
        "\n",
        "    plt.axvline(cutoff, color='black', linestyle='--', label=f'Critical value = {cutoff:.2f}')\n",
        "    plt.title('Type 1 and Type 2 Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Significance level (Type 1 error, α): {alpha}\")\n",
        "    print(f\"Type 2 error (β) given true mean {true_mean}: {beta:.4f}\")\n",
        "    print(f\"Power of the test (1 - β): {1 - beta:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "plot_type1_type2_errors(pop_mean=100, pop_std=15, sample_size=30, alpha=0.05, true_mean=110)\n",
        "\n",
        " #6\n",
        " import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Example sample data (two independent groups)\n",
        "group1 = np.array([23, 21, 19, 24, 22, 20, 25])\n",
        "group2 = np.array([30, 29, 28, 35, 32, 31, 33])\n",
        "\n",
        "# Perform independent two-sample t-test\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis at α={alpha}. The means are significantly different.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis at α={alpha}. No significant difference between means.\")\n",
        "#7\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_rel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example paired sample data (e.g., before and after treatment)\n",
        "before = np.array([85, 88, 90, 86, 87, 89, 91])\n",
        "after = np.array([88, 90, 92, 89, 90, 91, 93])\n",
        "\n",
        "# Perform paired t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "print(f\"Paired T-test statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis at α={alpha}. Significant difference between paired samples.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis at α={alpha}. No significant difference between paired samples.\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "# Plot paired points\n",
        "plt.plot(range(len(before)), before, 'o-', label='Before')\n",
        "plt.plot(range(len(after)), after, 's-', label='After')\n",
        "\n",
        "# Connect pairs with lines\n",
        "for i in range(len(before)):\n",
        "    plt.plot([i, i], [before[i], after[i]], 'gray', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.xticks(range(len(before)), [f'Subject {i+1}' for i in range(len(before))])\n",
        "plt.ylabel('Measurement')\n",
        "plt.title('Paired Sample Comparison: Before vs After')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#8\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.stats import norm, ttest_1samp\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "# Population parameters (true)\n",
        "population_mean = 50\n",
        "population_std = 10\n",
        "\n",
        "# Sample parameters\n",
        "sample_size = 30\n",
        "\n",
        "# Simulate sample data with a true mean slightly different from population_mean\n",
        "true_sample_mean = 52\n",
        "sample_data = np.random.normal(loc=true_sample_mean, scale=population_std, size=sample_size)\n",
        "\n",
        "# Calculate sample mean and sample std dev\n",
        "sample_mean = np.mean(sample_data)\n",
        "sample_std = np.std(sample_data, ddof=1)\n",
        "\n",
        "print(f\"Sample mean: {sample_mean:.3f}\")\n",
        "print(f\"Sample standard deviation: {sample_std:.3f}\")\n",
        "\n",
        "# 1. One-sample Z-test (assumes population std dev known)\n",
        "def one_sample_z_test(sample_mean, population_mean, population_std, sample_size):\n",
        "    se = population_std / math.sqrt(sample_size)\n",
        "    z_stat = (sample_mean - population_mean) / se\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))  # two-tailed\n",
        "    return z_stat, p_value\n",
        "\n",
        "z_stat, z_p_value = one_sample_z_test(sample_mean, population_mean, population_std, sample_size)\n",
        "\n",
        "print(f\"\\nZ-test results:\")\n",
        "print(f\"Z-statistic = {z_stat:.4f}\")\n",
        "print(f\"P-value = {z_p_value:.4f}\")\n",
        "\n",
        "# 2. One-sample T-test (population std dev unknown)\n",
        "t_stat, t_p_value = ttest_1samp(sample_data, population_mean)\n",
        "\n",
        "print(f\"\\nT-test results:\")\n",
        "print(f\"T-statistic = {t_stat:.4f}\")\n",
        "print(f\"P-value = {t_p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\nInterpretation:\")\n",
        "for test_name, p_val in [('Z-test', z_p_value), ('T-test', t_p_value)]:\n",
        "    if p_val < alpha:\n",
        "        print(f\"{test_name}: Reject the null hypothesis (significant difference).\")\n",
        "    else:\n",
        "        print(f\"{test_name}: Fail to reject the null hypothesis (no significant difference).\")\n",
        "#9\n",
        "import math\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "def confidence_interval(sample_mean, sample_std, sample_size, confidence=0.95, population_std_known=False, population_std=None):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_mean: Mean of the sample\n",
        "    - sample_std: Standard deviation of the sample\n",
        "    - sample_size: Number of observations in the sample\n",
        "    - confidence: Confidence level (default 0.95)\n",
        "    - population_std_known: Boolean, True if population std dev known\n",
        "    - population_std: Population std dev if known\n",
        "\n",
        "    Returns:\n",
        "    - (lower_bound, upper_bound): Tuple representing confidence interval\n",
        "    \"\"\"\n",
        "    alpha = 1 - confidence\n",
        "    se = (population_std / math.sqrt(sample_size)) if population_std_known else (sample_std / math.sqrt(sample_size))\n",
        "\n",
        "    if population_std_known:\n",
        "        # Use Z-distribution\n",
        "        z_critical = norm.ppf(1 - alpha/2)\n",
        "        margin_of_error = z_critical * se\n",
        "    else:\n",
        "        # Use T-distribution\n",
        "        t_critical = t.ppf(1 - alpha/2, df=sample_size - 1)\n",
        "        margin_of_error = t_critical * se\n",
        "\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage\n",
        "sample_mean = 100\n",
        "sample_std = 15\n",
        "sample_size = 30\n",
        "confidence_level = 0.95\n",
        "\n",
        "ci_lower, ci_upper = confidence_interval(sample_mean, sample_std, sample_size, confidence=confidence_level)\n",
        "print(f\"{int(confidence_level*100)}% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "#10\n",
        "import math\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "def margin_of_error(sample_std, sample_size, confidence=0.95, population_std_known=False, population_std=None):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for a confidence interval.\n",
        "\n",
        "    Parameters:\n",
        "    - sample_std: Sample standard deviation\n",
        "    - sample_size: Number of samples\n",
        "    - confidence: Confidence level (default 0.95)\n",
        "    - population_std_known: Boolean, True if population std dev known\n",
        "    - population_std: Population std dev if known\n",
        "\n",
        "    Returns:\n",
        "    - margin_of_error: The margin of error value\n",
        "    \"\"\"\n",
        "    alpha = 1 - confidence\n",
        "    se = (population_std / math.sqrt(sample_size)) if population_std_known else (sample_std / math.sqrt(sample_size))\n",
        "\n",
        "    if population_std_known:\n",
        "        # Use Z-distribution\n",
        "        z_critical = norm.ppf(1 - alpha/2)\n",
        "        moe = z_critical * se\n",
        "    else:\n",
        "        # Use T-distribution\n",
        "        t_critical = t.ppf(1 - alpha/2, df=sample_size - 1)\n",
        "        moe = t_critical * se\n",
        "\n",
        "    return moe\n",
        "\n",
        "# Example usage:\n",
        "sample_std = 12.5\n",
        "sample_size = 40\n",
        "confidence_level = 0.95\n",
        "\n",
        "moe = margin_of_error(sample_std, sample_size, confidence=confidence_level)\n",
        "print(f\"Margin of Error at {int(confidence_level*100)}% confidence: ±{moe:.3f}\")\n",
        "#11\n",
        "def bayesian_inference(prior_disease, sensitivity, false_positive_rate):\n",
        "    \"\"\"\n",
        "    Calculate posterior probability P(Disease | Positive Test) using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "    - prior_disease: P(Disease)\n",
        "    - sensitivity: P(Positive | Disease)\n",
        "    - false_positive_rate: P(Positive | No Disease)\n",
        "\n",
        "    Returns:\n",
        "    - posterior: P(Disease | Positive)\n",
        "    \"\"\"\n",
        "    prior_no_disease = 1 - prior_disease\n",
        "\n",
        "    # Total probability of testing positive\n",
        "    p_positive = sensitivity * prior_disease + false_positive_rate * prior_no_disease\n",
        "\n",
        "    # Posterior probability using Bayes' Theorem\n",
        "    posterior = (sensitivity * prior_disease) / p_positive\n",
        "\n",
        "    return posterior\n",
        "\n",
        "# Given data\n",
        "prior_disease = 0.01\n",
        "sensitivity = 0.99\n",
        "false_positive_rate = 0.05\n",
        "\n",
        "posterior_prob = bayesian_inference(prior_disease, sensitivity, false_positive_rate)\n",
        "print(f\"Posterior probability of disease given positive test: {posterior_prob:.4f} ({posterior_prob*100:.2f}%)\")\n",
        "#12\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Example contingency table (observed frequencies)\n",
        "# Rows: Gender (Male, Female)\n",
        "# Columns: Preference (Like, Dislike)\n",
        "observed = np.array([[30, 10],  # Male\n",
        "                     [20, 40]]) # Female\n",
        "\n",
        "# Perform Chi-square test of independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"\\nReject the null hypothesis at α={alpha}: Variables are dependent.\")\n",
        "else:\n",
        "    print(f\"\\nFail to reject the null hypothesis at α={alpha}: Variables are independent.\")\n",
        "#13\n",
        "import numpy as np\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    \"\"\"\n",
        "    Calculate expected frequencies for a Chi-square test of independence.\n",
        "\n",
        "    Parameters:\n",
        "    - observed: 2D numpy array of observed frequencies\n",
        "\n",
        "    Returns:\n",
        "    - expected: 2D numpy array of expected frequencies\n",
        "    \"\"\"\n",
        "    # Row sums and column sums\n",
        "    row_sums = observed.sum(axis=1).reshape(-1, 1)  # column vector\n",
        "    col_sums = observed.sum(axis=0).reshape(1, -1)  # row vector\n",
        "    total = observed.sum()\n",
        "\n",
        "    # Expected frequencies formula: (row_sum * col_sum) / total\n",
        "    expected = (row_sums @ col_sums) / total\n",
        "\n",
        "    return expected\n",
        "\n",
        "# Example observed data (contingency table)\n",
        "observed = np.array([[30, 10],\n",
        "                     [20, 40]])\n",
        "\n",
        "expected = calculate_expected_frequencies(observed)\n",
        "print(\"Observed Frequencies:\")\n",
        "print(observed)\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(expected)\n",
        "#14\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed counts for categories\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected counts (must sum to same total as observed)\n",
        "expected = np.array([40, 40, 20])\n",
        "\n",
        "# Perform goodness-of-fit Chi-square test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: observed distribution differs significantly from expected.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: observed data fits expected distribution.\")\n",
        "#15\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "df = 5  # degrees of freedom\n",
        "x = np.linspace(0, 20, 500)\n",
        "y = chi2.pdf(x, df)\n",
        "\n",
        "plt.plot(x, y, label=f'Chi-square PDF (df={df})')\n",
        "plt.title('Chi-square Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#16\n",
        "from scipy.stats import f\n",
        "\n",
        "np.random.seed(0)\n",
        "sample1 = np.random.normal(0, 10, 30)\n",
        "sample2 = np.random.normal(0, 15, 30)\n",
        "\n",
        "var1 = np.var(sample1, ddof=1)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "f_stat = var1 / var2 if var1 > var2 else var2 / var1\n",
        "df1 = len(sample1) - 1\n",
        "df2 = len(sample2) - 1\n",
        "\n",
        "p_value = 1 - f.cdf(f_stat, df1, df2)\n",
        "p_value *= 2  # two-tailed test\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject null hypothesis: variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: no significant difference in variances.\")\n",
        "#17\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "group1 = np.random.normal(20, 5, 30)\n",
        "group2 = np.random.normal(22, 5, 30)\n",
        "group3 = np.random.normal(19, 5, 30)\n",
        "\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"ANOVA F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject null hypothesis: at least one group mean is different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: group means are similar.\")\n",
        "#18\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "groups = [group1, group2, group3]\n",
        "plt.boxplot(groups, labels=['Group1', 'Group2', 'Group3'])\n",
        "plt.title('One-way ANOVA Group Comparison')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "#19\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(groups):\n",
        "    # Normality\n",
        "    normality = [shapiro(g).pvalue > 0.05 for g in groups]\n",
        "    # Equal variances\n",
        "    equal_var = levene(*groups).pvalue > 0.05\n",
        "    return normality, equal_var\n",
        "\n",
        "normality_results, equal_variance = check_anova_assumptions(groups)\n",
        "print(\"Normality per group:\", normality_results)\n",
        "print(\"Equal variances assumption:\", equal_variance)\n",
        "#20\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulated dataset with two factors and a response\n",
        "data = pd.DataFrame({\n",
        "    'FactorA': np.repeat(['A1', 'A2'], 30),\n",
        "    'FactorB': np.tile(np.repeat(['B1', 'B2'], 15), 2),\n",
        "    'Response': np.random.randn(60) + np.repeat([0, 1], 30)\n",
        "})\n",
        "\n",
        "model = ols('Response ~ C(FactorA) * C(FactorB)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: interaction plot\n",
        "from statsmodels.graphics.factorplots import interaction_plot\n",
        "interaction_plot(data['FactorA'], data['FactorB'], data['Response'])\n",
        "plt.show()\n",
        "#21\n",
        "from scipy.stats import f\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df1, df2 = 5, 10\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title(f'F-Distribution PDF (df1={df1}, df2={df2})')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#22\n",
        "plt.boxplot(groups, labels=['Group1', 'Group2', 'Group3'])\n",
        "plt.title('Group Means Comparison')\n",
        "plt.ylabel('Values')\n",
        "plt.show()\n",
        "#23\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "np.random.seed(0)\n",
        "sample = np.random.normal(loc=50, scale=10, size=40)\n",
        "t_stat, p_val = ttest_1samp(sample, popmean=50)\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_val:.4f}\")\n",
        "#24\n",
        "from scipy.stats import chi2\n",
        "\n",
        "sample_var = np.var(sample, ddof=1)\n",
        "n = len(sample)\n",
        "pop_var = 100  # hypothesized variance\n",
        "\n",
        "chi_stat = (n - 1) * sample_var / pop_var\n",
        "p_val_left = chi2.cdf(chi_stat, df=n - 1)\n",
        "p_val_right = 1 - p_val_left\n",
        "\n",
        "print(f\"Chi-square stat: {chi_stat:.4f}\")\n",
        "print(f\"P-value (two-tailed): {2 * min(p_val_left, p_val_right):.4f}\")\n",
        "#25from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "count = np.array([45, 30])   # successes in groups\n",
        "nobs = np.array([100, 80])   # total observations in groups\n",
        "\n",
        "stat, pval = proportions_ztest(count, nobs)\n",
        "print(f\"Z-statistic: {stat:.4f}, P-value: {pval:.4f}\")\n",
        "#26\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Use previous samples sample1, sample2\n",
        "f_stat = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
        "df1, df2 = len(sample1) - 1, len(sample2) - 1\n",
        "\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "plt.plot(x, y, label='F-distribution')\n",
        "plt.axvline(f_stat, color='r', linestyle='--', label='F statistic')\n",
        "plt.legend()\n",
        "plt.title('F-distribution with F statistic')\n",
        "plt.show()\n",
        "#27\n",
        "# Simulate observed data from categories\n",
        "np.random.seed(0)\n",
        "observed = np.random.multinomial(100, [0.2, 0.5, 0.3])\n",
        "expected = np.array([20, 50, 30])\n",
        "\n",
        "chi2_stat, p_val = chisquare(f_obs=observed, f_exp=expected)\n",
        "print(f\"Chi-square stat: {chi2_stat:.4f}, P-value: {p_val:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4wN3M2m-QhNP",
        "outputId": "4bd5b2c9-5ddf-4a0b-842b-caebe2941276"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-3-2578b8f3106c>, line 125)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-2578b8f3106c>\"\u001b[0;36m, line \u001b[0;32m125\u001b[0m\n\u001b[0;31m    import numpy as np\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}